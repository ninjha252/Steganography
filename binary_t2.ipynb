{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7987df-05e5-44ac-9562-d27febbfffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55524/1786818454.py:7: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "2025-05-01 21:35:50.280887: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 21:35:50.291641: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746135350.304808   55524 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746135350.308883   55524 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-01 21:35:50.322359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "usage: ipykernel_launcher.py [-h] [--model {baseline,hp,twostream}]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/nitinjha/.local/share/jupyter/runtime/kernel-ab1b368c-033e-42f2-8626-74664013ad0c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitinjha/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pkg_resources import load_entry_point\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 0) CLI arguments\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "parser = argparse.ArgumentParser(description=\"Stego Classification Ablation\")\n",
    "parser.add_argument(\n",
    "    \"--model\", choices=[\"baseline\",\"hp\",\"twostream\"],\n",
    "    default=\"baseline\", help=\"Which architecture to train\"\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Configuration & reproducibility\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "STEGO_CSV   = Path(\"csv/stego_final.csv\")\n",
    "IMAGES_DIR  = Path(\"Images\")\n",
    "BATCH_SIZE  = 16\n",
    "EPOCHS      = 15\n",
    "LR          = 1e-3\n",
    "RANDOM_SEED = 42\n",
    "STEP_SIZE   = 5\n",
    "GAMMA       = 0.1\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2) DataFrame building & splitting\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(STEGO_CSV)\n",
    "df = df[df.method.isin([\"lsb\",\"iwt\"])].copy()\n",
    "df[\"binary_method\"] = \"stego\"\n",
    "df[\"img_path\"]      = df[\"stego_path\"]\n",
    "\n",
    "n_stego   = len(df)\n",
    "all_imgs  = list(IMAGES_DIR.glob(\"*\"))\n",
    "used      = set(Path(p).name for p in df[\"img_path\"])\n",
    "candidates= [str(p) for p in all_imgs if p.name not in used]\n",
    "none_samp = random.sample(candidates, n_stego)\n",
    "\n",
    "df_none = pd.DataFrame({\n",
    "    \"binary_method\": [\"none\"]*n_stego,\n",
    "    \"img_path\":      none_samp\n",
    "})\n",
    "df = pd.concat([df[[\"binary_method\",\"img_path\"]], df_none], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.30, stratify=df[\"binary_method\"], random_state=RANDOM_SEED\n",
    ")\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train, test_size=0.20, stratify=df_train[\"binary_method\"], random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Dataset & DataLoader\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "label_map = {\"none\":0, \"stego\":1}\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "class StegoDataset(Dataset):\n",
    "    def __init__(self, df, tf): \n",
    "        self.df, self.tf = df.reset_index(drop=True), tf\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        img = Image.open(row.img_path).convert(\"RGB\")\n",
    "        if self.tf: img = self.tf(img)\n",
    "        lbl = label_map[row.binary_method]\n",
    "        return img, lbl\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    StegoDataset(df_train, train_tf),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,  num_workers=4, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    StegoDataset(df_val, val_tf),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    StegoDataset(df_test, val_tf),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661cb76-4729-4ecc-af17-912b92c35199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Model definitions\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4.1) Baseline\n",
    "def make_baseline():\n",
    "    m = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    m.fc = nn.Linear(m.fc.in_features, 2)\n",
    "    return m\n",
    "\n",
    "# 4.2) HPNet\n",
    "class HPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # high-pass kernel\n",
    "        hp = torch.tensor([[-1,2,-1],[2,-4,2],[-1,2,-1]],dtype=torch.float32)\n",
    "        hp = hp.view(1,1,3,3)\n",
    "        self.hp = nn.Conv2d(3,1,3,1,bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.hp.weight[:] = hp.repeat(1,3,1,1)\n",
    "            self.hp.weight.requires_grad = False\n",
    "        base = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone = base\n",
    "        self.backbone.fc = nn.Linear(base.fc.in_features, 2)\n",
    "    def forward(self, x):\n",
    "        r = self.hp(x)             # → [B,1,H,W]\n",
    "        r = r.repeat(1,3,1,1)      # → [B,3,H,W]\n",
    "        return self.backbone(r)\n",
    "\n",
    "# 4.3) Two-Stream\n",
    "class TwoStreamNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # hp filter\n",
    "        hp = torch.tensor([[-1,2,-1],[2,-4,2],[-1,2,-1]],dtype=torch.float32)\n",
    "        hp = hp.view(1,1,3,3)\n",
    "        self.hp_f = nn.Conv2d(3,1,3,1,bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.hp_f.weight[:] = hp.repeat(1,3,1,1)\n",
    "            self.hp_f.weight.requires_grad=False\n",
    "        # raw backbone\n",
    "        b1 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        feat_dim = b1.fc.in_features\n",
    "        b1.fc = nn.Identity()\n",
    "        # hp backbone\n",
    "        b2 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        b2.fc = nn.Identity()\n",
    "        self.raw_b = b1\n",
    "        self.hp_b  = b2\n",
    "        self.cls   = nn.Linear(feat_dim*2, 2)\n",
    "    def forward(self, x):\n",
    "        raw_feat = self.raw_b(x)\n",
    "        hp_img   = self.hp_f(x).repeat(1,3,1,1)\n",
    "        hp_feat  = self.hp_b(hp_img)\n",
    "        cat      = torch.cat([raw_feat, hp_feat], dim=1)\n",
    "        return self.cls(cat)\n",
    "\n",
    "# instantiate chosen model\n",
    "if args.model==\"baseline\":\n",
    "    model = make_baseline().to(DEVICE)\n",
    "elif args.model==\"hp\":\n",
    "    model = HPNet().to(DEVICE)\n",
    "else:\n",
    "    model = TwoStreamNet().to(DEVICE)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Loss, optimizer, scheduler, logging\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "weights   = torch.tensor([1.0,1.5],device=DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "scheduler = StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "writer       = SummaryWriter(f\"runs/stego_{args.model}\")\n",
    "train_losses = []; val_losses = []\n",
    "train_accs   = []; val_accs   = []\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Train / Val loops\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    ls=correct=total=0\n",
    "    for imgs,lbls in tqdm(train_loader, desc=\"Train\", leave=False):\n",
    "        imgs,lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out,lbls)\n",
    "        loss.backward(); optimizer.step()\n",
    "        ls     += loss.item()*lbls.size(0)\n",
    "        preds   = out.argmax(1)\n",
    "        correct+= (preds==lbls).sum().item()\n",
    "        total  += lbls.size(0)\n",
    "    return ls/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate():\n",
    "    model.eval()\n",
    "    ls=correct=total=0\n",
    "    for imgs,lbls in tqdm(val_loader, desc=\"Val  \", leave=False):\n",
    "        imgs,lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "        out = model(imgs)\n",
    "        loss=criterion(out,lbls)\n",
    "        ls      += loss.item()*lbls.size(0)\n",
    "        preds   = out.argmax(1)\n",
    "        correct+= (preds==lbls).sum().item()\n",
    "        total  += lbls.size(0)\n",
    "    return ls/total, correct/total\n",
    "\n",
    "best_acc=0.0\n",
    "for e in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc = train_epoch()\n",
    "    val_loss, val_acc = validate()\n",
    "    scheduler.step()\n",
    "\n",
    "    train_losses.append(tr_loss); val_losses.append(val_loss)\n",
    "    train_accs.append(tr_acc);   val_accs.append(val_acc)\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", tr_loss, e)\n",
    "    writer.add_scalar(\"Loss/val\",   val_loss, e)\n",
    "    writer.add_scalar(\"Acc/train\",  tr_acc, e)\n",
    "    writer.add_scalar(\"Acc/val\",    val_acc, e)\n",
    "\n",
    "    print(f\"[{args.model}] Epoch {e}/{EPOCHS}  \"\n",
    "          f\"Tr: {tr_loss:.4f}/{tr_acc:.3f}  \"\n",
    "          f\"Val: {val_loss:.4f}/{val_acc:.3f}\")\n",
    "\n",
    "    if val_acc>best_acc:\n",
    "        best_acc=val_acc\n",
    "        torch.save(model.state_dict(), f\"best_{args.model}.pth\")\n",
    "        print(\" → new best!\")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Plot curves\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "plt.figure()\n",
    "plt.plot(range(1,EPOCHS+1), train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(range(1,EPOCHS+1), val_losses,   label=\"Val   Loss\", marker='o')\n",
    "plt.title(\"Loss\"); plt.xlabel(\"Epoch\"); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,EPOCHS+1), train_accs, label=\"Train Acc\", marker='o')\n",
    "plt.plot(range(1,EPOCHS+1), val_accs,   label=\"Val   Acc\", marker='o')\n",
    "plt.title(\"Accuracy\"); plt.xlabel(\"Epoch\"); plt.legend(); plt.show()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 8) Test inference & metrics\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "model.load_state_dict(torch.load(f\"best_{args.model}.pth\"))\n",
    "model.eval()\n",
    "\n",
    "ALL_L, ALL_P, ALL_PROB = [], [], []\n",
    "with torch.no_grad():\n",
    "    for imgs,lbls in test_loader:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        out  = model(imgs)\n",
    "        prob = torch.softmax(out,dim=1)[:,1].cpu().numpy()\n",
    "        pred = out.argmax(1).cpu().numpy()\n",
    "\n",
    "        ALL_L.extend(lbls.numpy())\n",
    "        ALL_P.extend(pred)\n",
    "        ALL_PROB.extend(prob)\n",
    "\n",
    "# optimal threshold\n",
    "fpr,tpr,thr = roc_curve(ALL_L, ALL_PROB)\n",
    "opt = thr[np.argmax(tpr-fpr)]\n",
    "print(\"Optimal thr:\", opt)\n",
    "\n",
    "# confusion @ 0.5\n",
    "cm = confusion_matrix(ALL_L, ALL_P)\n",
    "ConfusionMatrixDisplay(cm, display_labels=[\"none\",\"stego\"]).plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (0.5)\"); plt.show()\n",
    "\n",
    "print(classification_report(ALL_L, ALL_P, target_names=[\"none\",\"stego\"]))\n",
    "\n",
    "# ROC\n",
    "auc = roc_auc_score(ALL_L, ALL_PROB)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr, label=f\"AUC={auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.title(\"ROC Curve\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63124161-f78e-4405-bbc8-31a94fd40933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f1923-5311-4b51-a8a3-d2b8cb217478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2dffa-7980-4ef4-8692-7e28571c05c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd571f7-e445-4915-a693-aa0876450865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
