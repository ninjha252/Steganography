{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61582a34-fd95-4cd6-8634-b7773006ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pywt\n",
    "from skimage.filters import sobel_h, sobel_v\n",
    "import glob\n",
    "\n",
    "def extract_features(df, img_root_col=\"img_path\"):\n",
    "    feats = []\n",
    "    for idx, row in df.iterrows():\n",
    "        path = row[img_root_col]\n",
    "        if not os.path.isfile(path):\n",
    "            # skip missing\n",
    "            continue\n",
    "\n",
    "        # --- load and gray-scale ---\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "\n",
    "        # --- 1) spatial residual stats (for LSB) ---\n",
    "        #   compute horizontal & vertical Sobel residuals\n",
    "        rx = sobel_h(arr)\n",
    "        ry = sobel_v(arr)\n",
    "        res = np.stack([rx, ry], axis=0)\n",
    "        # summary stats: mean & var of each residual band\n",
    "        stat_spatial = []\n",
    "        for band in res:\n",
    "            stat_spatial += [band.mean(), band.var()]\n",
    "\n",
    "        # --- 2) wavelet subband energies (for IWT) ---\n",
    "        # 2-level Haar DWT\n",
    "        coeffs = pywt.wavedec2(arr, wavelet='haar', level=2)\n",
    "        # coeffs = [cA2, (cH2,cV2,cD2), (cH1,cV1,cD1)]\n",
    "        stat_wave = []\n",
    "        # skip the final approximation (cA2), focus on detail bands\n",
    "        for level in coeffs[1:]:\n",
    "            for subband in level:\n",
    "                stat_wave.append(np.sum(subband**2) / subband.size)\n",
    "\n",
    "        # --- assemble ---\n",
    "        feature_vector = stat_spatial + stat_wave\n",
    "        feats.append({\n",
    "            \"idx\": idx,\n",
    "            **{f\"f{i}\": v for i, v in enumerate(feature_vector)},\n",
    "            \"label\": row[\"label\"]\n",
    "        })\n",
    "\n",
    "    feat_df = pd.DataFrame(feats).set_index(\"idx\")\n",
    "    return feat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9482e16-02b0-4c3d-be30-9605aef3257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3897, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>-0.001223</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>lsb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.038068</td>\n",
       "      <td>0.018195</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>lsb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>0.024196</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>lsb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>0.035603</td>\n",
       "      <td>0.037020</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>lsb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.024225</td>\n",
       "      <td>0.039782</td>\n",
       "      <td>0.047584</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>lsb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "idx                                                                         \n",
       "0   -0.001066  0.003528 -0.001223  0.003756  0.010723  0.010088  0.001403   \n",
       "1   -0.000023  0.023723 -0.000202  0.018495  0.053284  0.038068  0.018195   \n",
       "2    0.001033  0.009781  0.000423  0.009553  0.024196  0.024039  0.006649   \n",
       "3    0.000268  0.014513 -0.000260  0.014876  0.035603  0.037020  0.008028   \n",
       "4   -0.000143  0.020455  0.000291  0.024225  0.039782  0.047584  0.024700   \n",
       "\n",
       "           f7        f8        f9 label  \n",
       "idx                                      \n",
       "0    0.001453  0.001587  0.000087   lsb  \n",
       "1    0.014879  0.012256  0.004988   lsb  \n",
       "2    0.005074  0.004710  0.001067   lsb  \n",
       "3    0.007574  0.007590  0.001265   lsb  \n",
       "4    0.013742  0.016766  0.007745   lsb  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ——— build your DataFrame ———\n",
    "STEGO_CSV = \"./csv/stego_final.csv\"\n",
    "df = pd.read_csv(STEGO_CSV)\n",
    "df = df[df.method.isin([\"lsb\",\"iwt\"])].copy()\n",
    "df[\"label\"]    = df[\"method\"]\n",
    "df[\"img_path\"] = df[\"stego_path\"]\n",
    "\n",
    "# cover images from folder\n",
    "cover_paths = glob.glob(os.path.join(\"./initial\", \"*.*\"))  # adjust pattern if needed\n",
    "cover_df = pd.DataFrame({\"img_path\": cover_paths})\n",
    "cover_df[\"label\"] = \"none\"\n",
    "\n",
    "# full dataset\n",
    "full_df = pd.concat([df[[\"img_path\",\"label\"]], cover_df], ignore_index=True)\n",
    "\n",
    "# extract features\n",
    "feat_df = extract_features(full_df)\n",
    "print(feat_df.shape)\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa411933-08f1-4830-82cc-27bab5e8277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 ROC AUC: 0.5044\n",
      "Chosen probability threshold for ≥98% recall: 0.481\n",
      "At chosen threshold:\n",
      "  Accuracy : 0.4910\n",
      "  Precision: 0.4889\n",
      "  Recall   : 0.9816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7c0dd24610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "# ——— 1) Prepare the labels ———\n",
    "# assume `feat_df` is your DataFrame with f0–f9 and original \"label\"\n",
    "feat_df[\"stage1_label\"] = feat_df[\"label\"].isin([\"lsb\", \"iwt\"]).astype(int)\n",
    "\n",
    "# feature matrix & target vector\n",
    "X = feat_df[[f\"f{i}\" for i in range(10)]].values\n",
    "y = feat_df[\"stage1_label\"].values\n",
    "\n",
    "# ——— 2) Stratified train/test split ———\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ——— 3) Train a baseline model ———\n",
    "# you can swap in RandomForestClassifier(...) if you prefer\n",
    "clf = LogisticRegression(max_iter=1_000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ——— 4) Get predicted probabilities & ROC AUC ———\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"Stage 1 ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# ——— 5) Precision–Recall curve & threshold tuning ———\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# pick the highest threshold that still gives ≥98% recall\n",
    "desired_recall = 0.98\n",
    "# recall[0] corresponds to threshold=1.0; thresholds array is one shorter than recall\n",
    "idxs = np.where(recall[:-1] >= desired_recall)[0]\n",
    "if len(idxs) > 0:\n",
    "    thresh = thresholds[idxs[-1]]\n",
    "else:\n",
    "    thresh = 0.5  # fallback\n",
    "print(f\"Chosen probability threshold for ≥{desired_recall*100:.0f}% recall: {thresh:.3f}\")\n",
    "\n",
    "# ——— 6) Evaluate at this threshold ———\n",
    "y_pred = (y_proba >= thresh).astype(int)\n",
    "print(\"At chosen threshold:\")\n",
    "print(f\"  Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"  Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# ——— 7) (Optional) Inspect the confusion matrix ———\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=[\"cover\",\"stego\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a79dab9-21a4-4158-94ba-dd1fe4c94e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 threshold for ≥98% recall: 0.481\n",
      "\n",
      "--- Stage 2 (LSB vs IWT) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lsb       0.25      1.00      0.40       189\n",
      "         iwt       0.00      0.00      0.00       574\n",
      "\n",
      "    accuracy                           0.25       763\n",
      "   macro avg       0.12      0.50      0.20       763\n",
      "weighted avg       0.06      0.25      0.10       763\n",
      "\n",
      "\n",
      "--- End-to-end classification (none/lsb/iwt) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.59      0.03      0.05       400\n",
      "         lsb       0.25      0.97      0.39       194\n",
      "         iwt       0.00      0.00      0.00       186\n",
      "\n",
      "    accuracy                           0.26       780\n",
      "   macro avg       0.28      0.33      0.15       780\n",
      "weighted avg       0.36      0.26      0.12       780\n",
      "\n",
      "           pred_none  pred_lsb  pred_iwt\n",
      "true_none         10       390         0\n",
      "true_lsb           5       189         0\n",
      "true_iwt           2       184         0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "# 1) Prepare features & labels\n",
    "X = feat_df[[f\"f{i}\" for i in range(10)]].values\n",
    "y_stage1 = feat_df[\"label\"].isin([\"lsb\",\"iwt\"]).astype(int).values  # 1=stego, 0=cover\n",
    "y_orig   = feat_df[\"label\"].values                                  # \"none\",\"lsb\",\"iwt\"\n",
    "\n",
    "# 2) Stratified train/test split (keep y_orig for Stage 2)\n",
    "X_train, X_test, y1_train, y1_test, y_orig_train, y_orig_test = train_test_split(\n",
    "    X, y_stage1, y_orig,\n",
    "    test_size=0.2,\n",
    "    stratify=y_stage1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Train Stage 1: Stego vs Cover\n",
    "clf1 = LogisticRegression(max_iter=1_000, random_state=42)\n",
    "clf1.fit(X_train, y1_train)\n",
    "proba1_test = clf1.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 4) Pick threshold for ≥98% recall on stego\n",
    "prec, rec, th = precision_recall_curve(y1_test, proba1_test)\n",
    "idx = np.where(rec[:-1] >= 0.98)[0]\n",
    "thr = th[idx[-1]] if len(idx)>0 else 0.5\n",
    "print(f\"Stage 1 threshold for ≥98% recall: {thr:.3f}\")\n",
    "\n",
    "# 5) Mask out test/train stego sets\n",
    "mask1_train = clf1.predict_proba(X_train)[:,1] >= thr  # boolean mask on X_train\n",
    "mask1_test  = proba1_test                     >= thr  # boolean mask on X_test\n",
    "\n",
    "# 6) Build Stage 2 training data (only stego)\n",
    "X2_train = X_train[mask1_train]\n",
    "y2_train = np.where(y_orig_train[mask1_train]==\"lsb\", 0, 1)  # 0=LSB, 1=IWT\n",
    "\n",
    "# 7) Train Stage 2 with class balancing\n",
    "clf2 = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=2_000,\n",
    "    random_state=42\n",
    ")\n",
    "clf2.fit(X2_train, y2_train)\n",
    "\n",
    "# 8) Evaluate Stage 2 on its own filtered test set\n",
    "X2_test = X_test[mask1_test]\n",
    "y2_test = np.where(y_orig_test[mask1_test]==\"lsb\", 0, 1)\n",
    "y2_pred = clf2.predict(X2_test)\n",
    "\n",
    "print(\"\\n--- Stage 2 (LSB vs IWT) ---\")\n",
    "print(classification_report(y2_test, y2_pred, target_names=[\"lsb\",\"iwt\"]))\n",
    "\n",
    "# 9) End-to-end: build final_pred over the full X_test\n",
    "final_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    if not mask1_test[i]:\n",
    "        final_pred.append(\"none\")   # Stage 1 said \"cover\"\n",
    "    else:\n",
    "        p2 = clf2.predict(X_test[i].reshape(1,-1))[0]\n",
    "        final_pred.append(\"lsb\" if p2==0 else \"iwt\")\n",
    "\n",
    "# 10) Compare against y_orig_test\n",
    "print(\"\\n--- End-to-end classification (none/lsb/iwt) ---\")\n",
    "print(classification_report(y_orig_test, final_pred, labels=[\"none\",\"lsb\",\"iwt\"]))\n",
    "\n",
    "cm = confusion_matrix(y_orig_test, final_pred, labels=[\"none\",\"lsb\",\"iwt\"])\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"true_none\",\"true_lsb\",\"true_iwt\"],\n",
    "    columns=[\"pred_none\",\"pred_lsb\",\"pred_iwt\"]\n",
    ")\n",
    "print(cm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2e9e38-7783-4b4f-98fa-8ee6c98f4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1 threshold: 0.483 ===\n",
      " forwarded to Stage 2 → train: 2845, test: 699\n",
      "\n",
      " LogisticRegression (oversampled minority):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lsb       0.25      1.00      0.40       174\n",
      "         iwt       0.00      0.00      0.00       525\n",
      "\n",
      "    accuracy                           0.25       699\n",
      "   macro avg       0.12      0.50      0.20       699\n",
      "weighted avg       0.06      0.25      0.10       699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomForestClassifier (class_weight='balanced'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lsb       0.18      0.28      0.22       174\n",
      "         iwt       0.70      0.57      0.63       525\n",
      "\n",
      "    accuracy                           0.49       699\n",
      "   macro avg       0.44      0.42      0.42       699\n",
      "weighted avg       0.57      0.49      0.53       699\n",
      "\n",
      "\n",
      "=== Stage 1 threshold: 0.482 ===\n",
      " forwarded to Stage 2 → train: 2968, test: 731\n",
      "\n",
      " LogisticRegression (oversampled minority):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lsb       0.25      0.57      0.35       183\n",
      "         iwt       0.75      0.44      0.56       548\n",
      "\n",
      "    accuracy                           0.47       731\n",
      "   macro avg       0.50      0.50      0.45       731\n",
      "weighted avg       0.63      0.47      0.50       731\n",
      "\n",
      "\n",
      " RandomForestClassifier (class_weight='balanced'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lsb       0.17      0.26      0.21       183\n",
      "         iwt       0.70      0.58      0.63       548\n",
      "\n",
      "    accuracy                           0.50       731\n",
      "   macro avg       0.44      0.42      0.42       731\n",
      "weighted avg       0.57      0.50      0.53       731\n",
      "\n",
      "\n",
      "=== Stage 1 threshold: 0.481 ===\n",
      " forwarded to Stage 2 → train: 3060, test: 763\n",
      "\n",
      " LogisticRegression (oversampled minority):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lsb       0.25      1.00      0.40       189\n",
      "         iwt       0.00      0.00      0.00       574\n",
      "\n",
      "    accuracy                           0.25       763\n",
      "   macro avg       0.12      0.50      0.20       763\n",
      "weighted avg       0.06      0.25      0.10       763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nitinjha/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomForestClassifier (class_weight='balanced'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lsb       0.16      0.25      0.20       189\n",
      "         iwt       0.70      0.59      0.64       574\n",
      "\n",
      "    accuracy                           0.50       763\n",
      "   macro avg       0.43      0.42      0.42       763\n",
      "weighted avg       0.57      0.50      0.53       763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ——— 1) Prepare features & labels ———\n",
    "X = feat_df[[f\"f{i}\" for i in range(10)]].values\n",
    "y_stage1 = feat_df[\"label\"].isin([\"lsb\",\"iwt\"]).astype(int).values  # 1=stego, 0=cover\n",
    "y_orig   = feat_df[\"label\"].values                                  # \"none\",\"lsb\",\"iwt\"\n",
    "\n",
    "# ——— 2) Train/test split ———\n",
    "X_train, X_test, y1_train, y1_test, y_orig_train, y_orig_test = train_test_split(\n",
    "    X, y_stage1, y_orig,\n",
    "    test_size=0.2,\n",
    "    stratify=y_stage1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ——— 3) Train Stage 1 classifier ———\n",
    "clf1 = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf1.fit(X_train, y1_train)\n",
    "proba1_test = clf1.predict_proba(X_test)[:,1]\n",
    "\n",
    "# ——— 4) Compute precision–recall curve ———\n",
    "prec, rec, th = precision_recall_curve(y1_test, proba1_test)\n",
    "\n",
    "# ——— 5) Define recall targets & find thresholds ———\n",
    "recall_targets = [0.90, 0.95, 0.98]\n",
    "thresholds = []\n",
    "for tgt in recall_targets:\n",
    "    idxs = np.where(rec[:-1] >= tgt)[0]\n",
    "    if len(idxs):\n",
    "        thresholds.append(th[idxs[-1]])\n",
    "    else:\n",
    "        thresholds.append(0.5)\n",
    "\n",
    "# ——— 6) Loop over thresholds & evaluate Stage 2 under each ———\n",
    "for thr in thresholds:\n",
    "    # 6a) Mask out stego for train & test\n",
    "    mask_train = clf1.predict_proba(X_train)[:,1] >= thr\n",
    "    mask_test  = proba1_test                    >= thr\n",
    "\n",
    "    print(f\"\\n=== Stage 1 threshold: {thr:.3f} ===\")\n",
    "    print(f\" forwarded to Stage 2 → train: {mask_train.sum()}, test: {mask_test.sum()}\")\n",
    "\n",
    "    # 6b) Build Stage 2 datasets\n",
    "    X2_train = X_train[mask_train]\n",
    "    y2_train = np.where(y_orig_train[mask_train]==\"lsb\", 0, 1)  # 0=LSB,1=IWT\n",
    "    X2_test  = X_test[mask_test]\n",
    "    y2_test  = np.where(y_orig_test[mask_test]==\"lsb\", 0, 1)\n",
    "\n",
    "    # 6c) Oversample minority class for logistic regression\n",
    "    maj = 0 if (y2_train==0).sum() > (y2_train==1).sum() else 1\n",
    "    min_ = 1-maj\n",
    "    X_min = X2_train[y2_train==min_]\n",
    "    y_min = y2_train[y2_train==min_]\n",
    "    X_ups, y_ups = resample(\n",
    "        X_min, y_min,\n",
    "        replace=True,\n",
    "        n_samples=(y2_train==maj).sum(),\n",
    "        random_state=42\n",
    "    )\n",
    "    X2_bal = np.vstack([X2_train[y2_train==maj], X_ups])\n",
    "    y2_bal = np.concatenate([y2_train[y2_train==maj], y_ups])\n",
    "\n",
    "    # 6d) Train & evaluate oversampled Logistic Regression\n",
    "    clf_log = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf_log.fit(X2_bal, y2_bal)\n",
    "    y2_pred_log = clf_log.predict(X2_test)\n",
    "    print(\"\\n LogisticRegression (oversampled minority):\")\n",
    "    print(classification_report(y2_test, y2_pred_log, target_names=[\"lsb\",\"iwt\"]))\n",
    "\n",
    "    # 6e) Train & evaluate RandomForest with balanced class weights\n",
    "    clf_rf = RandomForestClassifier(\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf_rf.fit(X2_train, y2_train)\n",
    "    y2_pred_rf = clf_rf.predict(X2_test)\n",
    "    print(\"\\n RandomForestClassifier (class_weight='balanced'):\")\n",
    "    print(classification_report(y2_test, y2_pred_rf, target_names=[\"lsb\",\"iwt\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d99759-7845-48e4-918b-d20d1c73e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " threshold         stage2_model  accuracy  macro_precision  macro_recall  macro_f1\n",
      "  0.483406        random_forest  0.292308         0.343345      0.363753  0.278077\n",
      "  0.482047 logistic_oversampled  0.273077         0.370720      0.345271  0.263228\n",
      "  0.482047        random_forest  0.284615         0.367624      0.365539  0.262667\n",
      "  0.481232        random_forest  0.265385         0.355652      0.357907  0.232004\n",
      "  0.483406 logistic_oversampled  0.278205         0.259930      0.334802  0.189497\n",
      "  0.481232 logistic_oversampled  0.255128         0.278647      0.333076  0.147649\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ——— 0) Prepare features & labels ———\n",
    "X = feat_df[[f\"f{i}\" for i in range(10)]].values\n",
    "y_stage1 = feat_df[\"label\"].isin([\"lsb\",\"iwt\"]).astype(int).values  # 1=stego, 0=cover\n",
    "y_orig   = feat_df[\"label\"].values                                  # \"none\",\"lsb\",\"iwt\"\n",
    "\n",
    "# ——— 1) Split once ———\n",
    "X_train, X_test, y1_train, y1_test, y_orig_train, y_orig_test = train_test_split(\n",
    "    X, y_stage1, y_orig,\n",
    "    test_size=0.2, stratify=y_stage1, random_state=42\n",
    ")\n",
    "\n",
    "# ——— 2) Fit Stage 1 model ———\n",
    "stage1 = LogisticRegression(max_iter=1000, random_state=42)\n",
    "stage1.fit(X_train, y1_train)\n",
    "proba1_test = stage1.predict_proba(X_test)[:,1]\n",
    "\n",
    "# ——— 3) Find thresholds for desired recall targets ———\n",
    "prec, rec, th = precision_recall_curve(y1_test, proba1_test)\n",
    "recall_targets = [0.90, 0.95, 0.98]\n",
    "thresholds = []\n",
    "for tgt in recall_targets:\n",
    "    idxs = np.where(rec[:-1] >= tgt)[0]\n",
    "    thresholds.append(th[idxs[-1]] if len(idxs) else 0.5)\n",
    "\n",
    "# ——— 4) Evaluate end-to-end over thresholds & Stage 2 models ———\n",
    "results = []\n",
    "for thr in thresholds:\n",
    "    # masks\n",
    "    mask_train = stage1.predict_proba(X_train)[:,1] >= thr\n",
    "    mask_test  = proba1_test                   >= thr\n",
    "\n",
    "    # build Stage2 train/test\n",
    "    X2_train = X_train[mask_train]\n",
    "    y2_train = np.where(y_orig_train[mask_train]==\"lsb\", 0, 1)  # 0=LSB,1=IWT\n",
    "    X2_test  = X_test[mask_test]\n",
    "    y2_test  = np.where(y_orig_test[mask_test]==\"lsb\", 0, 1)\n",
    "\n",
    "    # 4a) Oversampled Logistic Regression\n",
    "    #   balance minority by up-sampling\n",
    "    maj = 0 if (y2_train==0).sum() > (y2_train==1).sum() else 1\n",
    "    min_ = 1 - maj\n",
    "    X_min = X2_train[y2_train==min_]\n",
    "    y_min = y2_train[y2_train==min_]\n",
    "    X_up, y_up = resample(X_min, y_min,\n",
    "                         replace=True,\n",
    "                         n_samples=(y2_train==maj).sum(),\n",
    "                         random_state=42)\n",
    "    X2_bal = np.vstack([X2_train[y2_train==maj], X_up])\n",
    "    y2_bal = np.concatenate([y2_train[y2_train==maj], y_up])\n",
    "\n",
    "    clf_log = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf_log.fit(X2_bal, y2_bal)\n",
    "\n",
    "    # 4b) RandomForest with built-in class balancing\n",
    "    clf_rf = RandomForestClassifier(\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf_rf.fit(X2_train, y2_train)\n",
    "\n",
    "    # helper to run end-to-end\n",
    "    def eval_e2e(model, name):\n",
    "        preds = []\n",
    "        for i in range(len(X_test)):\n",
    "            if not mask_test[i]:\n",
    "                preds.append(\"none\")\n",
    "            else:\n",
    "                p2 = model.predict(X_test[i].reshape(1,-1))[0]\n",
    "                preds.append(\"lsb\" if p2==0 else \"iwt\")\n",
    "        return {\n",
    "            \"threshold\": thr,\n",
    "            \"stage2_model\": name,\n",
    "            \"accuracy\": accuracy_score(y_orig_test, preds),\n",
    "            \"macro_precision\": precision_score(y_orig_test, preds, average=\"macro\", zero_division=0),\n",
    "            \"macro_recall\":    recall_score   (y_orig_test, preds, average=\"macro\"),\n",
    "            \"macro_f1\":        f1_score       (y_orig_test, preds, average=\"macro\"),\n",
    "        }\n",
    "\n",
    "    results.append(eval_e2e(clf_log, \"logistic_oversampled\"))\n",
    "    results.append(eval_e2e(clf_rf,  \"random_forest\"))\n",
    "\n",
    "# ——— 5) Show summary ———\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df.sort_values(by=\"macro_f1\", ascending=False).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b7f04-75ee-4a15-aee9-5f916471fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
